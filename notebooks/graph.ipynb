{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lung cancer classification with Graph Convolutional Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"README.md\"):\n",
    "    os.chdir(\"../\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for the ML part\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "# for the graph part\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_networkx, from_networkx\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from scripts.gcn import GCN, train, test, train_loop\n",
    "BATCH_SIZE = 16\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import dataset from csv files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GSDMB</th>\n",
       "      <th>TXN</th>\n",
       "      <th>SLC5A1</th>\n",
       "      <th>NSUN3</th>\n",
       "      <th>HSPA13</th>\n",
       "      <th>SOX9</th>\n",
       "      <th>ZKSCAN5</th>\n",
       "      <th>AMACR</th>\n",
       "      <th>LOC101060275</th>\n",
       "      <th>LOC101928625</th>\n",
       "      <th>...</th>\n",
       "      <th>CLGN</th>\n",
       "      <th>TMEM242</th>\n",
       "      <th>SERPINI1</th>\n",
       "      <th>TTC3</th>\n",
       "      <th>CD74</th>\n",
       "      <th>ZBTB18</th>\n",
       "      <th>REC8</th>\n",
       "      <th>MARC2</th>\n",
       "      <th>YWHAE</th>\n",
       "      <th>PRSS12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM93997</th>\n",
       "      <td>0.140096</td>\n",
       "      <td>0.235407</td>\n",
       "      <td>0.171271</td>\n",
       "      <td>0.183405</td>\n",
       "      <td>0.155741</td>\n",
       "      <td>0.132806</td>\n",
       "      <td>0.133945</td>\n",
       "      <td>0.136854</td>\n",
       "      <td>0.201459</td>\n",
       "      <td>0.188271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158699</td>\n",
       "      <td>0.170411</td>\n",
       "      <td>0.169404</td>\n",
       "      <td>0.224789</td>\n",
       "      <td>0.244948</td>\n",
       "      <td>0.113263</td>\n",
       "      <td>0.215222</td>\n",
       "      <td>0.155076</td>\n",
       "      <td>0.162765</td>\n",
       "      <td>0.162176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM94019</th>\n",
       "      <td>0.139721</td>\n",
       "      <td>0.220102</td>\n",
       "      <td>0.178908</td>\n",
       "      <td>0.183668</td>\n",
       "      <td>0.138633</td>\n",
       "      <td>0.150779</td>\n",
       "      <td>0.125344</td>\n",
       "      <td>0.139069</td>\n",
       "      <td>0.217829</td>\n",
       "      <td>0.154159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142984</td>\n",
       "      <td>0.169939</td>\n",
       "      <td>0.157350</td>\n",
       "      <td>0.218183</td>\n",
       "      <td>0.242422</td>\n",
       "      <td>0.110154</td>\n",
       "      <td>0.208866</td>\n",
       "      <td>0.156494</td>\n",
       "      <td>0.135190</td>\n",
       "      <td>0.152349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM94020</th>\n",
       "      <td>0.143053</td>\n",
       "      <td>0.202522</td>\n",
       "      <td>0.179960</td>\n",
       "      <td>0.181274</td>\n",
       "      <td>0.130426</td>\n",
       "      <td>0.155367</td>\n",
       "      <td>0.127912</td>\n",
       "      <td>0.137341</td>\n",
       "      <td>0.207420</td>\n",
       "      <td>0.142284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128292</td>\n",
       "      <td>0.176204</td>\n",
       "      <td>0.156956</td>\n",
       "      <td>0.206328</td>\n",
       "      <td>0.238198</td>\n",
       "      <td>0.114715</td>\n",
       "      <td>0.211555</td>\n",
       "      <td>0.152307</td>\n",
       "      <td>0.118662</td>\n",
       "      <td>0.161834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             GSDMB       TXN    SLC5A1     NSUN3    HSPA13      SOX9   \n",
       "GSM93997  0.140096  0.235407  0.171271  0.183405  0.155741  0.132806  \\\n",
       "GSM94019  0.139721  0.220102  0.178908  0.183668  0.138633  0.150779   \n",
       "GSM94020  0.143053  0.202522  0.179960  0.181274  0.130426  0.155367   \n",
       "\n",
       "           ZKSCAN5    AMACR   LOC101060275   LOC101928625   ...      CLGN   \n",
       "GSM93997  0.133945  0.136854       0.201459       0.188271  ...  0.158699  \\\n",
       "GSM94019  0.125344  0.139069       0.217829       0.154159  ...  0.142984   \n",
       "GSM94020  0.127912  0.137341       0.207420       0.142284  ...  0.128292   \n",
       "\n",
       "           TMEM242  SERPINI1     TTC3       CD74    ZBTB18      REC8   \n",
       "GSM93997  0.170411  0.169404  0.224789  0.244948  0.113263  0.215222  \\\n",
       "GSM94019  0.169939  0.157350  0.218183  0.242422  0.110154  0.208866   \n",
       "GSM94020  0.176204  0.156956  0.206328  0.238198  0.114715  0.211555   \n",
       "\n",
       "             MARC2     YWHAE    PRSS12  \n",
       "GSM93997  0.155076  0.162765  0.162176  \n",
       "GSM94019  0.156494  0.135190  0.152349  \n",
       "GSM94020  0.152307  0.118662  0.161834  \n",
       "\n",
       "[3 rows x 141 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degenes = pd.read_csv('./data/final/degenes.csv', index_col=0)\n",
    "pdata = pd.read_csv('./data/final/pdata_nan_filled.csv', index_col=0)\n",
    "\n",
    "degenes_t = degenes.T\n",
    "degenes_t.columns = [x.split('///')[0] for x in degenes_t.columns]\n",
    "degenes = degenes_t.T\n",
    "degenes = degenes/10\n",
    "degenes_t = degenes.T/10\n",
    "\n",
    "matrix = pd.read_csv('data/final/adj_matrix.csv', index_col=0)\n",
    "matrix = matrix.drop('cancer_status', axis=1).drop('cancer_status', axis=0)\n",
    "\n",
    "degenes_t.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>biomarker_score</th>\n",
       "      <th>cancer_status</th>\n",
       "      <th>gender</th>\n",
       "      <th>&gt;3cm</th>\n",
       "      <th>packyears</th>\n",
       "      <th>hemopytsis</th>\n",
       "      <th>lymphadenopathy</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>subjective_assessment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM93997</th>\n",
       "      <td>34.0</td>\n",
       "      <td>-2.253540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM94019</th>\n",
       "      <td>63.0</td>\n",
       "      <td>8.900589</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM94020</th>\n",
       "      <td>61.0</td>\n",
       "      <td>9.954619</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM94021</th>\n",
       "      <td>69.0</td>\n",
       "      <td>-3.460146</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM94022</th>\n",
       "      <td>61.0</td>\n",
       "      <td>1.543728</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM98871</th>\n",
       "      <td>62.0</td>\n",
       "      <td>6.628599</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM98872</th>\n",
       "      <td>62.0</td>\n",
       "      <td>3.834675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM98873</th>\n",
       "      <td>66.0</td>\n",
       "      <td>-0.549258</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM98874</th>\n",
       "      <td>65.0</td>\n",
       "      <td>6.642173</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM98875</th>\n",
       "      <td>65.0</td>\n",
       "      <td>9.112242</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age  biomarker_score  cancer_status  gender  >3cm  packyears   \n",
       "GSM93997  34.0        -2.253540            0.0     1.0   0.0       17.0  \\\n",
       "GSM94019  63.0         8.900589            1.0     1.0   1.0       75.0   \n",
       "GSM94020  61.0         9.954619            1.0     1.0   1.0       80.0   \n",
       "GSM94021  69.0        -3.460146            1.0     1.0   0.0       70.0   \n",
       "GSM94022  61.0         1.543728            1.0     1.0   0.0       80.0   \n",
       "...        ...              ...            ...     ...   ...        ...   \n",
       "GSM98871  62.0         6.628599            1.0     1.0   0.0       67.0   \n",
       "GSM98872  62.0         3.834675            1.0     1.0   1.0       72.0   \n",
       "GSM98873  66.0        -0.549258            1.0     1.0   1.0       61.0   \n",
       "GSM98874  65.0         6.642173            1.0     1.0   1.0       65.0   \n",
       "GSM98875  65.0         9.112242            1.0     1.0   0.0       68.0   \n",
       "\n",
       "          hemopytsis  lymphadenopathy  smoking_status  subjective_assessment  \n",
       "GSM93997         0.0              0.0             0.0                    0.0  \n",
       "GSM94019         0.0              1.0             0.0                    1.0  \n",
       "GSM94020         0.0              1.0             0.0                    1.0  \n",
       "GSM94021         0.0              1.0             1.0                    1.0  \n",
       "GSM94022         0.0              1.0             0.0                    1.0  \n",
       "...              ...              ...             ...                    ...  \n",
       "GSM98871         0.0              1.0             0.0                    1.0  \n",
       "GSM98872         0.0              1.0             0.0                    1.0  \n",
       "GSM98873         0.0              1.0             0.0                    1.0  \n",
       "GSM98874         0.0              1.0             0.0                    1.0  \n",
       "GSM98875         0.0              1.0             0.0                    1.0  \n",
       "\n",
       "[192 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop nan in pdata\n",
    "pdata = pdata.dropna(axis=0)\n",
    "pdata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler and StandardScaler pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GSM93997</th>\n",
       "      <th>GSM94019</th>\n",
       "      <th>GSM94020</th>\n",
       "      <th>GSM94021</th>\n",
       "      <th>GSM94022</th>\n",
       "      <th>GSM94023</th>\n",
       "      <th>GSM94024</th>\n",
       "      <th>GSM94025</th>\n",
       "      <th>GSM94026</th>\n",
       "      <th>GSM94027</th>\n",
       "      <th>...</th>\n",
       "      <th>GSM98797</th>\n",
       "      <th>GSM98798</th>\n",
       "      <th>GSM98799</th>\n",
       "      <th>GSM98800</th>\n",
       "      <th>GSM98801</th>\n",
       "      <th>GSM98871</th>\n",
       "      <th>GSM98872</th>\n",
       "      <th>GSM98873</th>\n",
       "      <th>GSM98874</th>\n",
       "      <th>GSM98875</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSDMB</th>\n",
       "      <td>0.206948</td>\n",
       "      <td>0.209339</td>\n",
       "      <td>0.233461</td>\n",
       "      <td>0.320483</td>\n",
       "      <td>0.206750</td>\n",
       "      <td>0.211192</td>\n",
       "      <td>0.189032</td>\n",
       "      <td>0.115259</td>\n",
       "      <td>0.224393</td>\n",
       "      <td>0.178037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203517</td>\n",
       "      <td>0.188561</td>\n",
       "      <td>0.255286</td>\n",
       "      <td>0.272566</td>\n",
       "      <td>0.155407</td>\n",
       "      <td>0.216968</td>\n",
       "      <td>0.293979</td>\n",
       "      <td>0.241238</td>\n",
       "      <td>0.261283</td>\n",
       "      <td>0.237032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TXN</th>\n",
       "      <td>0.845322</td>\n",
       "      <td>0.751053</td>\n",
       "      <td>0.657096</td>\n",
       "      <td>0.793263</td>\n",
       "      <td>0.816640</td>\n",
       "      <td>0.737990</td>\n",
       "      <td>0.832710</td>\n",
       "      <td>0.820180</td>\n",
       "      <td>0.822031</td>\n",
       "      <td>0.839329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783206</td>\n",
       "      <td>0.737515</td>\n",
       "      <td>0.788049</td>\n",
       "      <td>0.819971</td>\n",
       "      <td>0.799605</td>\n",
       "      <td>0.566921</td>\n",
       "      <td>0.341013</td>\n",
       "      <td>0.715559</td>\n",
       "      <td>0.461597</td>\n",
       "      <td>0.785306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLC5A1</th>\n",
       "      <td>0.415754</td>\n",
       "      <td>0.473435</td>\n",
       "      <td>0.496373</td>\n",
       "      <td>0.494284</td>\n",
       "      <td>0.472976</td>\n",
       "      <td>0.437425</td>\n",
       "      <td>0.493254</td>\n",
       "      <td>0.478358</td>\n",
       "      <td>0.453937</td>\n",
       "      <td>0.490949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446771</td>\n",
       "      <td>0.438553</td>\n",
       "      <td>0.476721</td>\n",
       "      <td>0.452521</td>\n",
       "      <td>0.411302</td>\n",
       "      <td>0.421924</td>\n",
       "      <td>0.508630</td>\n",
       "      <td>0.443029</td>\n",
       "      <td>0.481669</td>\n",
       "      <td>0.443907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        GSM93997  GSM94019  GSM94020  GSM94021  GSM94022  GSM94023  GSM94024   \n",
       "GSDMB   0.206948  0.209339  0.233461  0.320483  0.206750  0.211192  0.189032  \\\n",
       "TXN     0.845322  0.751053  0.657096  0.793263  0.816640  0.737990  0.832710   \n",
       "SLC5A1  0.415754  0.473435  0.496373  0.494284  0.472976  0.437425  0.493254   \n",
       "\n",
       "        GSM94025  GSM94026  GSM94027  ...  GSM98797  GSM98798  GSM98799   \n",
       "GSDMB   0.115259  0.224393  0.178037  ...  0.203517  0.188561  0.255286  \\\n",
       "TXN     0.820180  0.822031  0.839329  ...  0.783206  0.737515  0.788049   \n",
       "SLC5A1  0.478358  0.453937  0.490949  ...  0.446771  0.438553  0.476721   \n",
       "\n",
       "        GSM98800  GSM98801  GSM98871  GSM98872  GSM98873  GSM98874  GSM98875  \n",
       "GSDMB   0.272566  0.155407  0.216968  0.293979  0.241238  0.261283  0.237032  \n",
       "TXN     0.819971  0.799605  0.566921  0.341013  0.715559  0.461597  0.785306  \n",
       "SLC5A1  0.452521  0.411302  0.421924  0.508630  0.443029  0.481669  0.443907  \n",
       "\n",
       "[3 rows x 192 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min max scale\n",
    "degenes_scaled = pd.DataFrame(degenes, index=degenes.index, columns=degenes.columns)\n",
    "#degenes_scaled = degenes_scaled.applymap(lambda x: np.exp(x))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "degenes_scaled = pd.DataFrame(scaler.fit_transform(degenes_scaled), index=degenes_scaled.index, columns=degenes_scaled.columns)\n",
    "\n",
    "mmscaler = MinMaxScaler()\n",
    "degenes_scaled = pd.DataFrame(mmscaler.fit_transform(degenes_scaled), index=degenes_scaled.index, columns=degenes_scaled.columns)\n",
    "\n",
    "# minmax pdata\n",
    "pdata_scaled = pd.DataFrame(pdata, index=pdata.index, columns=pdata.columns)\n",
    "pdata_scaled = pd.DataFrame(scaler.fit_transform(pdata_scaled), index=pdata_scaled.index, columns=pdata_scaled.columns)\n",
    "pdata_scaled = pd.DataFrame(mmscaler.fit_transform(pdata_scaled), index=pdata_scaled.index, columns=pdata_scaled.columns)\n",
    "\n",
    "degenes_scaled.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>biomarker_score</th>\n",
       "      <th>cancer_status</th>\n",
       "      <th>gender</th>\n",
       "      <th>&gt;3cm</th>\n",
       "      <th>packyears</th>\n",
       "      <th>hemopytsis</th>\n",
       "      <th>lymphadenopathy</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>subjective_assessment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM93997</th>\n",
       "      <td>0.174603</td>\n",
       "      <td>0.409506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM94019</th>\n",
       "      <td>0.634921</td>\n",
       "      <td>0.721167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM94020</th>\n",
       "      <td>0.603175</td>\n",
       "      <td>0.750618</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age  biomarker_score  cancer_status  gender  >3cm  packyears   \n",
       "GSM93997  0.174603         0.409506            0.0     1.0   0.0   0.094444  \\\n",
       "GSM94019  0.634921         0.721167            1.0     1.0   1.0   0.416667   \n",
       "GSM94020  0.603175         0.750618            1.0     1.0   1.0   0.444444   \n",
       "\n",
       "          hemopytsis  lymphadenopathy  smoking_status  subjective_assessment  \n",
       "GSM93997         0.0              0.0             0.0                    0.0  \n",
       "GSM94019         0.0              1.0             0.0                    1.0  \n",
       "GSM94020         0.0              1.0             0.0                    1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdata_scaled.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building graph structure from adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = {}\n",
    "\n",
    "for i in range(0, len(degenes_scaled.columns)):\n",
    "    G = nx.from_pandas_adjacency(matrix)\n",
    "    G.remove_nodes_from(list(nx.isolates(G)))\n",
    "    nx.set_node_attributes(G, degenes_scaled.iloc[:,i].to_dict(), 'x')\n",
    "\n",
    "    for edge in G.edges:\n",
    "        G.edges[edge]['weight'] = 1\n",
    "\n",
    "    graphs[degenes_scaled.columns[i]] = G"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pytorch graph structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a geometric data object from the networkx for each graph\n",
    "data_list = []\n",
    "for key, value in graphs.items():\n",
    "    try:\n",
    "        cs = pdata.loc[key, 'cancer_status']\n",
    "\n",
    "        d = from_networkx(value)\n",
    "        d.x = torch.tensor([d[1]['x'] for d in value.nodes(data=True)], dtype=torch.float32)\n",
    "        d.x = d.x.view(-1, 1)\n",
    "\n",
    "        target = torch.tensor([[0, 1]], dtype=torch.float32) if cs == 1 else torch.tensor([[1, 0]], dtype=torch.float32)\n",
    "        additional_features = pdata.loc[key].drop(['cancer_status','subjective_assessment'], axis=0)\n",
    "        additional_features = additional_features.to_frame().T\n",
    "        additional_features = additional_features.astype('float32')\n",
    "\n",
    "        d.y = [target, torch.tensor(additional_features.values)]\n",
    "\n",
    "        data_list.append(d)\n",
    "    except:\n",
    "        KeyError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 29, 29)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split in train validation and test\n",
    "train_data, test_data = train_test_split(data_list, test_size=0.3, random_state=42)\n",
    "val_data, test_data = train_test_split(test_data, test_size=0.5, random_state=42)\n",
    "\n",
    "len(train_data), len(test_data), len(val_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create torch DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data:  Counter({1: 73, 0: 61})\n",
      "val_data:  Counter({1: 16, 0: 13})\n",
      "test_data:  Counter({1: 18, 0: 11})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "train_cancer_status = [torch.argmax(d.y[0]).item() for d in train_data]\n",
    "val_cancer_status = [torch.argmax(d.y[0]).item() for d in val_data]\n",
    "test_cancer_status = [torch.argmax(d.y[0]).item() for d in test_data]\n",
    "\n",
    "print('train_data: ', Counter(train_cancer_status))\n",
    "print('val_data: ', Counter(val_cancer_status))\n",
    "print('test_data: ', Counter(test_cancer_status))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, graph classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# autoreload \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from scripts.gcn import GCN, EarlyStopping, train_loop, test, GCNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(1, 256)\n",
      "  (lin1): Linear(in_features=264, out_features=32, bias=True)\n",
      "  (lin2): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = GCN(hidden_channels=256)\n",
    "print(model)\n",
    "\n",
    "# define training loop\n",
    "device = torch.device(\"cpu\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-3)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Train Loss: 0.2020, Train Acc: 0.7463, Val Loss: 0.1686, Val Acc: 0.8276\n",
      "Epoch: 001, Train Loss: 0.1847, Train Acc: 0.7612, Val Loss: 0.1363, Val Acc: 0.8621\n",
      "Epoch: 002, Train Loss: 0.1736, Train Acc: 0.7463, Val Loss: 0.1166, Val Acc: 0.8621\n",
      "Epoch: 003, Train Loss: 0.1688, Train Acc: 0.7761, Val Loss: 0.1135, Val Acc: 0.8621\n",
      "Epoch: 004, Train Loss: 0.1651, Train Acc: 0.7687, Val Loss: 0.1087, Val Acc: 0.8966\n",
      "Epoch: 005, Train Loss: 0.1627, Train Acc: 0.7761, Val Loss: 0.1088, Val Acc: 0.8966\n",
      "Epoch: 006, Train Loss: 0.1597, Train Acc: 0.7761, Val Loss: 0.1078, Val Acc: 0.8621\n",
      "Epoch: 007, Train Loss: 0.1570, Train Acc: 0.7761, Val Loss: 0.1062, Val Acc: 0.8621\n",
      "Epoch: 008, Train Loss: 0.1552, Train Acc: 0.7836, Val Loss: 0.1047, Val Acc: 0.8966\n",
      "Epoch: 009, Train Loss: 0.1523, Train Acc: 0.7836, Val Loss: 0.1073, Val Acc: 0.8966\n",
      "Epoch: 010, Train Loss: 0.1495, Train Acc: 0.7836, Val Loss: 0.1042, Val Acc: 0.8966\n",
      "Epoch: 011, Train Loss: 0.1462, Train Acc: 0.7836, Val Loss: 0.1045, Val Acc: 0.8966\n",
      "Epoch: 012, Train Loss: 0.1430, Train Acc: 0.7761, Val Loss: 0.1050, Val Acc: 0.8276\n",
      "Epoch: 013, Train Loss: 0.1391, Train Acc: 0.7761, Val Loss: 0.1019, Val Acc: 0.8621\n",
      "Epoch: 014, Train Loss: 0.1357, Train Acc: 0.7761, Val Loss: 0.1019, Val Acc: 0.8276\n",
      "Epoch: 015, Train Loss: 0.1344, Train Acc: 0.7836, Val Loss: 0.0993, Val Acc: 0.8276\n",
      "Epoch: 016, Train Loss: 0.1288, Train Acc: 0.7910, Val Loss: 0.0946, Val Acc: 0.8966\n",
      "Epoch: 017, Train Loss: 0.1282, Train Acc: 0.7910, Val Loss: 0.0956, Val Acc: 0.8276\n",
      "Epoch: 018, Train Loss: 0.1254, Train Acc: 0.7985, Val Loss: 0.0936, Val Acc: 0.8621\n",
      "Epoch: 019, Train Loss: 0.1223, Train Acc: 0.7985, Val Loss: 0.0914, Val Acc: 0.8621\n",
      "Epoch: 020, Train Loss: 0.1232, Train Acc: 0.7910, Val Loss: 0.0964, Val Acc: 0.8276\n",
      "Epoch: 021, Train Loss: 0.1182, Train Acc: 0.8134, Val Loss: 0.0829, Val Acc: 0.8966\n",
      "Epoch: 022, Train Loss: 0.1179, Train Acc: 0.8134, Val Loss: 0.0883, Val Acc: 0.8621\n",
      "Epoch: 023, Train Loss: 0.1148, Train Acc: 0.8134, Val Loss: 0.0837, Val Acc: 0.8966\n",
      "Epoch: 024, Train Loss: 0.1137, Train Acc: 0.8209, Val Loss: 0.0924, Val Acc: 0.8276\n",
      "Epoch: 025, Train Loss: 0.1120, Train Acc: 0.8134, Val Loss: 0.0829, Val Acc: 0.8621\n",
      "Epoch: 026, Train Loss: 0.1103, Train Acc: 0.8284, Val Loss: 0.0902, Val Acc: 0.8621\n",
      "Epoch: 027, Train Loss: 0.1089, Train Acc: 0.8433, Val Loss: 0.0824, Val Acc: 0.8966\n",
      "Epoch: 028, Train Loss: 0.1073, Train Acc: 0.8433, Val Loss: 0.0861, Val Acc: 0.8966\n",
      "Epoch: 029, Train Loss: 0.1057, Train Acc: 0.8433, Val Loss: 0.0871, Val Acc: 0.8621\n",
      "Epoch: 030, Train Loss: 0.1069, Train Acc: 0.8284, Val Loss: 0.0875, Val Acc: 0.8621\n",
      "Epoch: 031, Train Loss: 0.1041, Train Acc: 0.8507, Val Loss: 0.0779, Val Acc: 0.8966\n",
      "Epoch: 032, Train Loss: 0.1010, Train Acc: 0.8582, Val Loss: 0.0828, Val Acc: 0.8966\n",
      "Epoch: 033, Train Loss: 0.1042, Train Acc: 0.8358, Val Loss: 0.0902, Val Acc: 0.8621\n",
      "Epoch: 034, Train Loss: 0.0989, Train Acc: 0.8582, Val Loss: 0.0823, Val Acc: 0.9310\n",
      "Epoch: 035, Train Loss: 0.1048, Train Acc: 0.8433, Val Loss: 0.0911, Val Acc: 0.8276\n",
      "Epoch: 036, Train Loss: 0.0976, Train Acc: 0.8507, Val Loss: 0.0786, Val Acc: 0.8966\n",
      "Epoch: 037, Train Loss: 0.0971, Train Acc: 0.8657, Val Loss: 0.0793, Val Acc: 0.8966\n",
      "Epoch: 038, Train Loss: 0.1000, Train Acc: 0.8433, Val Loss: 0.0907, Val Acc: 0.7931\n",
      "Epoch: 039, Train Loss: 0.0956, Train Acc: 0.8657, Val Loss: 0.0864, Val Acc: 0.8621\n",
      "Epoch: 040, Train Loss: 0.0952, Train Acc: 0.8657, Val Loss: 0.0819, Val Acc: 0.8966\n",
      "Epoch: 041, Train Loss: 0.0988, Train Acc: 0.8358, Val Loss: 0.0866, Val Acc: 0.8621\n",
      "Epoch: 042, Train Loss: 0.0945, Train Acc: 0.8582, Val Loss: 0.0772, Val Acc: 0.8966\n",
      "Epoch: 043, Train Loss: 0.0914, Train Acc: 0.8731, Val Loss: 0.0730, Val Acc: 0.8966\n",
      "Epoch: 044, Train Loss: 0.0970, Train Acc: 0.8582, Val Loss: 0.0935, Val Acc: 0.8621\n",
      "Epoch: 045, Train Loss: 0.0931, Train Acc: 0.8507, Val Loss: 0.0852, Val Acc: 0.8621\n",
      "Epoch: 046, Train Loss: 0.0914, Train Acc: 0.8507, Val Loss: 0.0944, Val Acc: 0.8621\n",
      "Epoch: 047, Train Loss: 0.0945, Train Acc: 0.8582, Val Loss: 0.0830, Val Acc: 0.8966\n",
      "Epoch: 048, Train Loss: 0.0881, Train Acc: 0.8507, Val Loss: 0.0721, Val Acc: 0.8966\n",
      "Epoch: 049, Train Loss: 0.0958, Train Acc: 0.8582, Val Loss: 0.0925, Val Acc: 0.8621\n",
      "Epoch: 050, Train Loss: 0.0939, Train Acc: 0.8433, Val Loss: 0.0869, Val Acc: 0.8621\n",
      "Epoch: 051, Train Loss: 0.0883, Train Acc: 0.8507, Val Loss: 0.0760, Val Acc: 0.8966\n",
      "Epoch: 052, Train Loss: 0.1010, Train Acc: 0.8284, Val Loss: 0.0911, Val Acc: 0.8621\n",
      "Epoch: 053, Train Loss: 0.0938, Train Acc: 0.8657, Val Loss: 0.0922, Val Acc: 0.8621\n",
      "Epoch: 054, Train Loss: 0.0883, Train Acc: 0.8657, Val Loss: 0.0671, Val Acc: 0.9310\n",
      "Epoch: 055, Train Loss: 0.0996, Train Acc: 0.8358, Val Loss: 0.1089, Val Acc: 0.8621\n",
      "Epoch: 056, Train Loss: 0.0960, Train Acc: 0.8433, Val Loss: 0.0967, Val Acc: 0.8621\n",
      "Epoch: 057, Train Loss: 0.0891, Train Acc: 0.8507, Val Loss: 0.0626, Val Acc: 0.9310\n",
      "Epoch: 058, Train Loss: 0.0954, Train Acc: 0.8433, Val Loss: 0.1078, Val Acc: 0.8621\n",
      "Epoch: 059, Train Loss: 0.0952, Train Acc: 0.8806, Val Loss: 0.0814, Val Acc: 0.9310\n",
      "Epoch: 060, Train Loss: 0.0900, Train Acc: 0.8657, Val Loss: 0.0659, Val Acc: 0.8966\n",
      "Epoch: 061, Train Loss: 0.0992, Train Acc: 0.8433, Val Loss: 0.1100, Val Acc: 0.8621\n",
      "Epoch: 062, Train Loss: 0.0863, Train Acc: 0.8731, Val Loss: 0.0843, Val Acc: 0.8621\n",
      "Epoch: 063, Train Loss: 0.0849, Train Acc: 0.8731, Val Loss: 0.0757, Val Acc: 0.9310\n",
      "Epoch: 064, Train Loss: 0.0882, Train Acc: 0.8507, Val Loss: 0.0753, Val Acc: 0.8966\n",
      "Epoch: 065, Train Loss: 0.0873, Train Acc: 0.8731, Val Loss: 0.0828, Val Acc: 0.8966\n",
      "Epoch: 066, Train Loss: 0.0803, Train Acc: 0.8806, Val Loss: 0.0637, Val Acc: 0.9310\n",
      "Epoch: 067, Train Loss: 0.0886, Train Acc: 0.8582, Val Loss: 0.0981, Val Acc: 0.8621\n",
      "Epoch: 068, Train Loss: 0.0874, Train Acc: 0.8806, Val Loss: 0.1015, Val Acc: 0.8966\n",
      "Epoch: 069, Train Loss: 0.0810, Train Acc: 0.8955, Val Loss: 0.0681, Val Acc: 0.8966\n",
      "Epoch: 070, Train Loss: 0.1011, Train Acc: 0.8284, Val Loss: 0.1124, Val Acc: 0.8621\n",
      "Epoch: 071, Train Loss: 0.0897, Train Acc: 0.8881, Val Loss: 0.0844, Val Acc: 0.8966\n",
      "Epoch: 072, Train Loss: 0.0833, Train Acc: 0.8806, Val Loss: 0.0596, Val Acc: 0.9310\n",
      "Epoch: 073, Train Loss: 0.1033, Train Acc: 0.8507, Val Loss: 0.1074, Val Acc: 0.8621\n",
      "Epoch: 074, Train Loss: 0.0866, Train Acc: 0.9030, Val Loss: 0.0890, Val Acc: 0.8966\n",
      "Epoch: 075, Train Loss: 0.0833, Train Acc: 0.8657, Val Loss: 0.0877, Val Acc: 0.8621\n",
      "Epoch: 076, Train Loss: 0.0850, Train Acc: 0.8806, Val Loss: 0.0882, Val Acc: 0.8966\n",
      "Epoch: 077, Train Loss: 0.0780, Train Acc: 0.9179, Val Loss: 0.0712, Val Acc: 0.8966\n",
      "Epoch: 078, Train Loss: 0.0874, Train Acc: 0.8507, Val Loss: 0.0930, Val Acc: 0.8621\n",
      "Epoch: 079, Train Loss: 0.0873, Train Acc: 0.8806, Val Loss: 0.0998, Val Acc: 0.8966\n",
      "Epoch: 080, Train Loss: 0.0796, Train Acc: 0.9030, Val Loss: 0.0739, Val Acc: 0.8966\n",
      "Epoch: 081, Train Loss: 0.0867, Train Acc: 0.8507, Val Loss: 0.0733, Val Acc: 0.8966\n",
      "Epoch: 082, Train Loss: 0.0807, Train Acc: 0.9030, Val Loss: 0.0631, Val Acc: 0.8966\n",
      "Epoch: 083, Train Loss: 0.0771, Train Acc: 0.9104, Val Loss: 0.0650, Val Acc: 0.8966\n",
      "Epoch: 084, Train Loss: 0.0887, Train Acc: 0.8582, Val Loss: 0.0921, Val Acc: 0.8621\n",
      "Epoch: 085, Train Loss: 0.0777, Train Acc: 0.9104, Val Loss: 0.0813, Val Acc: 0.8621\n",
      "Epoch: 086, Train Loss: 0.0756, Train Acc: 0.9030, Val Loss: 0.0696, Val Acc: 0.8966\n",
      "Epoch: 087, Train Loss: 0.0849, Train Acc: 0.8657, Val Loss: 0.0833, Val Acc: 0.8621\n",
      "Epoch: 088, Train Loss: 0.0756, Train Acc: 0.9104, Val Loss: 0.0723, Val Acc: 0.8966\n",
      "Epoch: 089, Train Loss: 0.0767, Train Acc: 0.8955, Val Loss: 0.0647, Val Acc: 0.8966\n",
      "Epoch: 090, Train Loss: 0.0853, Train Acc: 0.8731, Val Loss: 0.0895, Val Acc: 0.8621\n",
      "Epoch: 091, Train Loss: 0.0756, Train Acc: 0.9179, Val Loss: 0.0719, Val Acc: 0.8966\n",
      "Epoch: 092, Train Loss: 0.0758, Train Acc: 0.9030, Val Loss: 0.0695, Val Acc: 0.8966\n",
      "Epoch: 093, Train Loss: 0.0865, Train Acc: 0.8731, Val Loss: 0.0964, Val Acc: 0.8621\n",
      "Epoch: 094, Train Loss: 0.0730, Train Acc: 0.9328, Val Loss: 0.0709, Val Acc: 0.8966\n",
      "Epoch: 095, Train Loss: 0.0777, Train Acc: 0.8955, Val Loss: 0.0878, Val Acc: 0.8621\n",
      "Epoch: 096, Train Loss: 0.0803, Train Acc: 0.8955, Val Loss: 0.0906, Val Acc: 0.8621\n",
      "Epoch: 097, Train Loss: 0.0723, Train Acc: 0.9254, Val Loss: 0.0680, Val Acc: 0.8966\n",
      "Epoch: 098, Train Loss: 0.0823, Train Acc: 0.8507, Val Loss: 0.0895, Val Acc: 0.8621\n",
      "Epoch: 099, Train Loss: 0.0782, Train Acc: 0.9030, Val Loss: 0.0862, Val Acc: 0.8621\n",
      "Epoch: 100, Train Loss: 0.0724, Train Acc: 0.9179, Val Loss: 0.0708, Val Acc: 0.8966\n",
      "Epoch: 101, Train Loss: 0.0843, Train Acc: 0.8507, Val Loss: 0.0993, Val Acc: 0.8621\n",
      "Epoch: 102, Train Loss: 0.0777, Train Acc: 0.9104, Val Loss: 0.0942, Val Acc: 0.8621\n",
      "Epoch: 103, Train Loss: 0.0735, Train Acc: 0.9179, Val Loss: 0.0732, Val Acc: 0.8966\n",
      "Epoch: 104, Train Loss: 0.0815, Train Acc: 0.8731, Val Loss: 0.0686, Val Acc: 0.8966\n",
      "Epoch: 105, Train Loss: 0.0784, Train Acc: 0.8955, Val Loss: 0.0653, Val Acc: 0.8966\n",
      "Epoch: 106, Train Loss: 0.0719, Train Acc: 0.9254, Val Loss: 0.0575, Val Acc: 0.8966\n",
      "Epoch: 107, Train Loss: 0.0835, Train Acc: 0.8507, Val Loss: 0.0823, Val Acc: 0.8621\n",
      "Epoch: 108, Train Loss: 0.0760, Train Acc: 0.8881, Val Loss: 0.0696, Val Acc: 0.8966\n",
      "Epoch: 109, Train Loss: 0.0722, Train Acc: 0.9328, Val Loss: 0.0688, Val Acc: 0.8966\n",
      "Epoch: 110, Train Loss: 0.0738, Train Acc: 0.9030, Val Loss: 0.0810, Val Acc: 0.8621\n",
      "Epoch: 111, Train Loss: 0.0757, Train Acc: 0.8731, Val Loss: 0.0746, Val Acc: 0.8966\n",
      "Epoch: 112, Train Loss: 0.0745, Train Acc: 0.9030, Val Loss: 0.0851, Val Acc: 0.8621\n",
      "Epoch: 113, Train Loss: 0.0690, Train Acc: 0.9328, Val Loss: 0.0689, Val Acc: 0.8966\n",
      "Epoch: 114, Train Loss: 0.0717, Train Acc: 0.9104, Val Loss: 0.0834, Val Acc: 0.8276\n",
      "Epoch: 115, Train Loss: 0.0708, Train Acc: 0.9104, Val Loss: 0.0769, Val Acc: 0.8966\n",
      "Epoch: 116, Train Loss: 0.0693, Train Acc: 0.9104, Val Loss: 0.0833, Val Acc: 0.8276\n",
      "Epoch: 117, Train Loss: 0.0691, Train Acc: 0.9104, Val Loss: 0.0835, Val Acc: 0.8276\n",
      "Epoch: 118, Train Loss: 0.0699, Train Acc: 0.8881, Val Loss: 0.0830, Val Acc: 0.8276\n",
      "Epoch: 119, Train Loss: 0.0704, Train Acc: 0.8955, Val Loss: 0.0817, Val Acc: 0.8276\n",
      "Epoch: 120, Train Loss: 0.0673, Train Acc: 0.9254, Val Loss: 0.0795, Val Acc: 0.8966\n",
      "Epoch: 121, Train Loss: 0.0683, Train Acc: 0.8881, Val Loss: 0.0739, Val Acc: 0.8621\n",
      "Epoch: 122, Train Loss: 0.0666, Train Acc: 0.9254, Val Loss: 0.0796, Val Acc: 0.8621\n",
      "Epoch: 123, Train Loss: 0.0673, Train Acc: 0.8955, Val Loss: 0.0710, Val Acc: 0.8621\n",
      "Epoch: 124, Train Loss: 0.0684, Train Acc: 0.9179, Val Loss: 0.0844, Val Acc: 0.8621\n",
      "Epoch: 125, Train Loss: 0.0634, Train Acc: 0.9328, Val Loss: 0.0711, Val Acc: 0.8621\n",
      "Epoch: 126, Train Loss: 0.0674, Train Acc: 0.9179, Val Loss: 0.0948, Val Acc: 0.8276\n",
      "Epoch: 127, Train Loss: 0.0671, Train Acc: 0.8955, Val Loss: 0.0840, Val Acc: 0.8621\n",
      "Epoch: 128, Train Loss: 0.0646, Train Acc: 0.9254, Val Loss: 0.0931, Val Acc: 0.8276\n",
      "Epoch: 129, Train Loss: 0.0662, Train Acc: 0.9030, Val Loss: 0.0806, Val Acc: 0.8621\n",
      "Epoch: 130, Train Loss: 0.0644, Train Acc: 0.9254, Val Loss: 0.1014, Val Acc: 0.8621\n",
      "Epoch: 131, Train Loss: 0.0696, Train Acc: 0.8806, Val Loss: 0.0801, Val Acc: 0.8966\n",
      "Epoch: 132, Train Loss: 0.0699, Train Acc: 0.9179, Val Loss: 0.1063, Val Acc: 0.8621\n",
      "Epoch: 133, Train Loss: 0.0622, Train Acc: 0.9179, Val Loss: 0.0771, Val Acc: 0.8276\n",
      "Epoch: 134, Train Loss: 0.0656, Train Acc: 0.9254, Val Loss: 0.1037, Val Acc: 0.8276\n",
      "Epoch: 135, Train Loss: 0.0634, Train Acc: 0.9254, Val Loss: 0.0867, Val Acc: 0.8621\n",
      "Epoch: 136, Train Loss: 0.0682, Train Acc: 0.9030, Val Loss: 0.0988, Val Acc: 0.8276\n",
      "Epoch: 137, Train Loss: 0.0682, Train Acc: 0.8806, Val Loss: 0.0931, Val Acc: 0.8276\n",
      "Epoch: 138, Train Loss: 0.0594, Train Acc: 0.9403, Val Loss: 0.0944, Val Acc: 0.7931\n",
      "Epoch: 139, Train Loss: 0.0718, Train Acc: 0.8657, Val Loss: 0.1001, Val Acc: 0.8621\n",
      "Epoch: 140, Train Loss: 0.0617, Train Acc: 0.9328, Val Loss: 0.0924, Val Acc: 0.8276\n",
      "Epoch: 141, Train Loss: 0.0727, Train Acc: 0.8657, Val Loss: 0.1006, Val Acc: 0.8621\n",
      "Epoch: 142, Train Loss: 0.0621, Train Acc: 0.9328, Val Loss: 0.0735, Val Acc: 0.8276\n",
      "Epoch: 143, Train Loss: 0.0644, Train Acc: 0.9403, Val Loss: 0.1065, Val Acc: 0.8621\n",
      "Epoch: 144, Train Loss: 0.0697, Train Acc: 0.8806, Val Loss: 0.0992, Val Acc: 0.8621\n",
      "Epoch: 145, Train Loss: 0.0655, Train Acc: 0.9254, Val Loss: 0.0706, Val Acc: 0.8966\n",
      "Epoch: 146, Train Loss: 0.0675, Train Acc: 0.9328, Val Loss: 0.1127, Val Acc: 0.8276\n",
      "Epoch: 147, Train Loss: 0.0696, Train Acc: 0.8731, Val Loss: 0.1148, Val Acc: 0.8276\n",
      "Epoch: 148, Train Loss: 0.0739, Train Acc: 0.8731, Val Loss: 0.0981, Val Acc: 0.8276\n",
      "Epoch: 149, Train Loss: 0.0640, Train Acc: 0.9403, Val Loss: 0.0813, Val Acc: 0.8621\n",
      "Epoch: 150, Train Loss: 0.0816, Train Acc: 0.8582, Val Loss: 0.1145, Val Acc: 0.8621\n",
      "Epoch: 151, Train Loss: 0.0740, Train Acc: 0.9030, Val Loss: 0.0907, Val Acc: 0.8276\n",
      "Epoch: 152, Train Loss: 0.0679, Train Acc: 0.9179, Val Loss: 0.0699, Val Acc: 0.8276\n",
      "Epoch: 153, Train Loss: 0.0635, Train Acc: 0.9104, Val Loss: 0.0925, Val Acc: 0.8276\n",
      "Epoch: 154, Train Loss: 0.0648, Train Acc: 0.9254, Val Loss: 0.0855, Val Acc: 0.8621\n",
      "Epoch: 155, Train Loss: 0.0741, Train Acc: 0.8657, Val Loss: 0.0921, Val Acc: 0.8276\n",
      "Epoch: 156, Train Loss: 0.0625, Train Acc: 0.9328, Val Loss: 0.0903, Val Acc: 0.8621\n",
      "-----------------------\n",
      "EARLY STOPPING \tBest train loss: 0.0719\tBest val loss: 0.0575\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "train_loop(\n",
    "    model, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    epochs=1000,\n",
    "    early_stopping=EarlyStopping(patience=50, delta=0.0001, verbose=True),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "128 hidden units, 0.2 dropout, 1e-3 L2, 0.001 learning rate\n",
    "Best train loss: 0.1018\tBest val loss: 0.1436"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7586\n"
     ]
    }
   ],
   "source": [
    "acc, loss = test(test_loader, model, criterion)\n",
    "print(f'Test Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_set = train_data.copy()\n",
    "for x in val_data:\n",
    "    dev_set.append(x)\n",
    "\n",
    "dev_loader = DataLoader(dev_set, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(1, 64)\n",
      "  (lin1): Linear(in_features=72, out_features=32, bias=True)\n",
      "  (lin2): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n",
      "Epoch: 000, Train Loss: 0.1837, Train Acc: 0.7730, Val Loss: 0.1837, Val Acc: 0.7730\n",
      "Epoch: 001, Train Loss: 0.1755, Train Acc: 0.7607, Val Loss: 0.1755, Val Acc: 0.7607\n",
      "Epoch: 002, Train Loss: 0.1662, Train Acc: 0.7853, Val Loss: 0.1662, Val Acc: 0.7853\n",
      "Epoch: 003, Train Loss: 0.1577, Train Acc: 0.7853, Val Loss: 0.1577, Val Acc: 0.7853\n",
      "Epoch: 004, Train Loss: 0.1525, Train Acc: 0.7914, Val Loss: 0.1525, Val Acc: 0.7914\n",
      "Epoch: 005, Train Loss: 0.1466, Train Acc: 0.8037, Val Loss: 0.1466, Val Acc: 0.8037\n",
      "Epoch: 006, Train Loss: 0.1422, Train Acc: 0.7975, Val Loss: 0.1422, Val Acc: 0.7975\n",
      "Epoch: 007, Train Loss: 0.1418, Train Acc: 0.8037, Val Loss: 0.1418, Val Acc: 0.8037\n",
      "Epoch: 008, Train Loss: 0.1363, Train Acc: 0.8037, Val Loss: 0.1363, Val Acc: 0.8037\n",
      "Epoch: 009, Train Loss: 0.1321, Train Acc: 0.8098, Val Loss: 0.1321, Val Acc: 0.8098\n",
      "Epoch: 010, Train Loss: 0.1261, Train Acc: 0.8160, Val Loss: 0.1261, Val Acc: 0.8160\n",
      "Epoch: 011, Train Loss: 0.1226, Train Acc: 0.8160, Val Loss: 0.1226, Val Acc: 0.8160\n",
      "Epoch: 012, Train Loss: 0.1191, Train Acc: 0.8221, Val Loss: 0.1191, Val Acc: 0.8221\n",
      "Epoch: 013, Train Loss: 0.1160, Train Acc: 0.8405, Val Loss: 0.1160, Val Acc: 0.8405\n",
      "Epoch: 014, Train Loss: 0.1126, Train Acc: 0.8405, Val Loss: 0.1126, Val Acc: 0.8405\n",
      "Epoch: 015, Train Loss: 0.1097, Train Acc: 0.8466, Val Loss: 0.1097, Val Acc: 0.8466\n",
      "Epoch: 016, Train Loss: 0.1083, Train Acc: 0.8528, Val Loss: 0.1083, Val Acc: 0.8528\n",
      "Epoch: 017, Train Loss: 0.1068, Train Acc: 0.8650, Val Loss: 0.1068, Val Acc: 0.8650\n",
      "Epoch: 018, Train Loss: 0.1051, Train Acc: 0.8712, Val Loss: 0.1051, Val Acc: 0.8712\n",
      "Epoch: 019, Train Loss: 0.1025, Train Acc: 0.8712, Val Loss: 0.1025, Val Acc: 0.8712\n",
      "Epoch: 020, Train Loss: 0.1013, Train Acc: 0.8712, Val Loss: 0.1013, Val Acc: 0.8712\n",
      "Epoch: 021, Train Loss: 0.1008, Train Acc: 0.8712, Val Loss: 0.1008, Val Acc: 0.8712\n",
      "Epoch: 022, Train Loss: 0.1008, Train Acc: 0.8712, Val Loss: 0.1008, Val Acc: 0.8712\n",
      "Epoch: 023, Train Loss: 0.0987, Train Acc: 0.8712, Val Loss: 0.0987, Val Acc: 0.8712\n",
      "Epoch: 024, Train Loss: 0.0966, Train Acc: 0.8712, Val Loss: 0.0966, Val Acc: 0.8712\n",
      "Epoch: 025, Train Loss: 0.0962, Train Acc: 0.8773, Val Loss: 0.0962, Val Acc: 0.8773\n",
      "Epoch: 026, Train Loss: 0.0967, Train Acc: 0.8712, Val Loss: 0.0967, Val Acc: 0.8712\n",
      "Epoch: 027, Train Loss: 0.0973, Train Acc: 0.8712, Val Loss: 0.0973, Val Acc: 0.8712\n",
      "Epoch: 028, Train Loss: 0.0970, Train Acc: 0.8773, Val Loss: 0.0970, Val Acc: 0.8773\n",
      "Epoch: 029, Train Loss: 0.0934, Train Acc: 0.8712, Val Loss: 0.0934, Val Acc: 0.8712\n",
      "Epoch: 030, Train Loss: 0.0934, Train Acc: 0.8773, Val Loss: 0.0934, Val Acc: 0.8773\n",
      "Epoch: 031, Train Loss: 0.0928, Train Acc: 0.8773, Val Loss: 0.0928, Val Acc: 0.8773\n",
      "Epoch: 032, Train Loss: 0.0941, Train Acc: 0.8773, Val Loss: 0.0941, Val Acc: 0.8773\n",
      "Epoch: 033, Train Loss: 0.0957, Train Acc: 0.8773, Val Loss: 0.0957, Val Acc: 0.8773\n",
      "Epoch: 034, Train Loss: 0.0951, Train Acc: 0.8773, Val Loss: 0.0951, Val Acc: 0.8773\n",
      "Epoch: 035, Train Loss: 0.0912, Train Acc: 0.8834, Val Loss: 0.0912, Val Acc: 0.8834\n",
      "Epoch: 036, Train Loss: 0.0898, Train Acc: 0.8834, Val Loss: 0.0898, Val Acc: 0.8834\n",
      "Epoch: 037, Train Loss: 0.0922, Train Acc: 0.8834, Val Loss: 0.0922, Val Acc: 0.8834\n",
      "Epoch: 038, Train Loss: 0.0912, Train Acc: 0.8834, Val Loss: 0.0912, Val Acc: 0.8834\n",
      "Epoch: 039, Train Loss: 0.0942, Train Acc: 0.8773, Val Loss: 0.0942, Val Acc: 0.8773\n",
      "Epoch: 040, Train Loss: 0.0969, Train Acc: 0.8773, Val Loss: 0.0969, Val Acc: 0.8773\n",
      "Epoch: 041, Train Loss: 0.0908, Train Acc: 0.8773, Val Loss: 0.0908, Val Acc: 0.8773\n",
      "Epoch: 042, Train Loss: 0.0888, Train Acc: 0.8834, Val Loss: 0.0888, Val Acc: 0.8834\n",
      "Epoch: 043, Train Loss: 0.0905, Train Acc: 0.8957, Val Loss: 0.0905, Val Acc: 0.8957\n",
      "Epoch: 044, Train Loss: 0.0905, Train Acc: 0.8834, Val Loss: 0.0905, Val Acc: 0.8834\n",
      "Epoch: 045, Train Loss: 0.0924, Train Acc: 0.8773, Val Loss: 0.0924, Val Acc: 0.8773\n",
      "Epoch: 046, Train Loss: 0.0991, Train Acc: 0.8712, Val Loss: 0.0991, Val Acc: 0.8712\n",
      "Epoch: 047, Train Loss: 0.0922, Train Acc: 0.8773, Val Loss: 0.0922, Val Acc: 0.8773\n",
      "Epoch: 048, Train Loss: 0.0877, Train Acc: 0.8773, Val Loss: 0.0877, Val Acc: 0.8773\n",
      "Epoch: 049, Train Loss: 0.0884, Train Acc: 0.8896, Val Loss: 0.0884, Val Acc: 0.8896\n",
      "Epoch: 050, Train Loss: 0.0885, Train Acc: 0.8896, Val Loss: 0.0885, Val Acc: 0.8896\n",
      "Epoch: 051, Train Loss: 0.0886, Train Acc: 0.8896, Val Loss: 0.0886, Val Acc: 0.8896\n",
      "Epoch: 052, Train Loss: 0.0948, Train Acc: 0.8773, Val Loss: 0.0948, Val Acc: 0.8773\n",
      "Epoch: 053, Train Loss: 0.0919, Train Acc: 0.8773, Val Loss: 0.0919, Val Acc: 0.8773\n",
      "Epoch: 054, Train Loss: 0.0881, Train Acc: 0.8834, Val Loss: 0.0881, Val Acc: 0.8834\n",
      "Epoch: 055, Train Loss: 0.0855, Train Acc: 0.8896, Val Loss: 0.0855, Val Acc: 0.8896\n",
      "Epoch: 056, Train Loss: 0.0869, Train Acc: 0.8896, Val Loss: 0.0869, Val Acc: 0.8896\n",
      "Epoch: 057, Train Loss: 0.0873, Train Acc: 0.8896, Val Loss: 0.0873, Val Acc: 0.8896\n",
      "Epoch: 058, Train Loss: 0.0870, Train Acc: 0.8834, Val Loss: 0.0870, Val Acc: 0.8834\n",
      "Epoch: 059, Train Loss: 0.0905, Train Acc: 0.8773, Val Loss: 0.0905, Val Acc: 0.8773\n",
      "Epoch: 060, Train Loss: 0.0899, Train Acc: 0.8773, Val Loss: 0.0899, Val Acc: 0.8773\n",
      "Epoch: 061, Train Loss: 0.0853, Train Acc: 0.8834, Val Loss: 0.0853, Val Acc: 0.8834\n",
      "Epoch: 062, Train Loss: 0.0838, Train Acc: 0.8834, Val Loss: 0.0838, Val Acc: 0.8834\n",
      "Epoch: 063, Train Loss: 0.0853, Train Acc: 0.8896, Val Loss: 0.0853, Val Acc: 0.8896\n",
      "Epoch: 064, Train Loss: 0.0849, Train Acc: 0.9018, Val Loss: 0.0849, Val Acc: 0.9018\n",
      "Epoch: 065, Train Loss: 0.0842, Train Acc: 0.8896, Val Loss: 0.0842, Val Acc: 0.8896\n",
      "Epoch: 066, Train Loss: 0.0888, Train Acc: 0.8834, Val Loss: 0.0888, Val Acc: 0.8834\n",
      "Epoch: 067, Train Loss: 0.0897, Train Acc: 0.8712, Val Loss: 0.0897, Val Acc: 0.8712\n",
      "Epoch: 068, Train Loss: 0.0869, Train Acc: 0.8896, Val Loss: 0.0869, Val Acc: 0.8896\n",
      "Epoch: 069, Train Loss: 0.0841, Train Acc: 0.8834, Val Loss: 0.0841, Val Acc: 0.8834\n",
      "Epoch: 070, Train Loss: 0.0821, Train Acc: 0.8834, Val Loss: 0.0821, Val Acc: 0.8834\n",
      "Epoch: 071, Train Loss: 0.0812, Train Acc: 0.8957, Val Loss: 0.0812, Val Acc: 0.8957\n",
      "Epoch: 072, Train Loss: 0.0825, Train Acc: 0.8957, Val Loss: 0.0825, Val Acc: 0.8957\n",
      "Epoch: 073, Train Loss: 0.0803, Train Acc: 0.9018, Val Loss: 0.0803, Val Acc: 0.9018\n",
      "Epoch: 074, Train Loss: 0.0825, Train Acc: 0.8896, Val Loss: 0.0825, Val Acc: 0.8896\n",
      "Epoch: 075, Train Loss: 0.0857, Train Acc: 0.8896, Val Loss: 0.0857, Val Acc: 0.8896\n",
      "Epoch: 076, Train Loss: 0.0889, Train Acc: 0.8896, Val Loss: 0.0889, Val Acc: 0.8896\n",
      "Epoch: 077, Train Loss: 0.0810, Train Acc: 0.8957, Val Loss: 0.0810, Val Acc: 0.8957\n",
      "Epoch: 078, Train Loss: 0.0787, Train Acc: 0.8896, Val Loss: 0.0787, Val Acc: 0.8896\n",
      "Min Loss reached: Epoch: 078, Train Loss: 0.0787, Train Acc: 0.8896\n"
     ]
    }
   ],
   "source": [
    "model = GCN(hidden_channels=64)\n",
    "print(model)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# define training loop\n",
    "device = torch.device(\"cpu\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-3)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "train_loop(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    dev_loader,\n",
    "    dev_loader,\n",
    "    epochs=1000,\n",
    "    verbose=True,\n",
    "    min_loss = 0.08\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8621\n"
     ]
    }
   ],
   "source": [
    "# test on test set\n",
    "acc, loss = test(test_loader, model, criterion)\n",
    "print(f'Test Accuracy: {acc:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "GCN(\n",
      "  (conv1): GCNConv(1, 256)\n",
      "  (lin1): Linear(in_features=264, out_features=32, bias=True)\n",
      "  (lin2): Linear(in_features=32, out_features=2, bias=True)\n",
      "  (bn1): BatchNorm(256)\n",
      ")\n",
      "Min Loss reached: Epoch: 100, Train Loss: 0.0994, Train Acc: 0.8516\n",
      "> Fold 1 trained. Test accuracy: 0.922\tTest loss 0.081\n",
      "GCN(\n",
      "  (conv1): GCNConv(1, 256)\n",
      "  (lin1): Linear(in_features=264, out_features=32, bias=True)\n",
      "  (lin2): Linear(in_features=32, out_features=2, bias=True)\n",
      "  (bn1): BatchNorm(256)\n",
      ")\n",
      "Min Loss reached: Epoch: 026, Train Loss: 0.0990, Train Acc: 0.8828\n",
      "> Fold 2 trained. Test accuracy: 0.812\tTest loss 0.137\n",
      "GCN(\n",
      "  (conv1): GCNConv(1, 256)\n",
      "  (lin1): Linear(in_features=264, out_features=32, bias=True)\n",
      "  (lin2): Linear(in_features=32, out_features=2, bias=True)\n",
      "  (bn1): BatchNorm(256)\n",
      ")\n",
      "Min Loss reached: Epoch: 023, Train Loss: 0.0992, Train Acc: 0.8984\n",
      "> Fold 3 trained. Test accuracy: 0.844\tTest loss 0.135\n",
      "--------------------\n",
      "REPORT\n",
      "Mean accuracy: 0.859 \n",
      "Mean loss: 0.118 \n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# autoreload \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from scripts.gcn import GCN, EarlyStopping, train_loop, test, GCNClassifier\n",
    "\n",
    "# lucky config K=3, rs=43, 256 hidden, 0.01 lr, 1e-3 wd\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=43)\n",
    "accuracies =[]\n",
    "losses = []\n",
    "counter = 1\n",
    "torch.manual_seed(42)\n",
    "for train_index, test_index in kf.split(data_list):\n",
    "\n",
    "    train_data = [data_list[i] for i in train_index]\n",
    "    # append the noisy data to the train data\n",
    "\n",
    "    train_data_noisy = train_data.copy()\n",
    "    \n",
    "    \"\"\"\n",
    "    for t in train_data_noisy:\n",
    "        t.x = t.x + (0.5**0.5)*torch.randn(t.x.shape)\n",
    "\n",
    "    for t in train_data_noisy:\n",
    "        train_data.append(t)\n",
    "    \"\"\"\n",
    "\n",
    "    test_data = [data_list[i] for i in test_index]\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model = GCN(hidden_channels=256)\n",
    "    print(model)\n",
    "\n",
    "    # define training loop\n",
    "    device = torch.device(\"cpu\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-3)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    train_loop(\n",
    "        model,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        epochs=1000,\n",
    "        verbose=False,\n",
    "        min_loss=0.1\n",
    "    )\n",
    "    model.eval()\n",
    "    acc, loss = test(test_loader, model, criterion)\n",
    "    accuracies.append(acc)\n",
    "    losses.append(loss)\n",
    "    print(f'> Fold {counter} trained. Test accuracy: {acc:.3f}\\tTest loss {loss:.3f}')\n",
    "    counter += 1\n",
    "\n",
    "# print mean accuracy and loss\n",
    "print('-'*20)\n",
    "print('REPORT')\n",
    "print(f'Mean accuracy: {np.mean(accuracies):.3f} ')\n",
    "print(f'Mean loss: {np.mean(losses):.3f} ')\n",
    "print('-'*20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "human protein atlas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
