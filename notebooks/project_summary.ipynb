{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project summary and data exploration. \n",
    "\n",
    "Will also be used to create the project summary report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"README.md\"):\n",
    "    os.chdir(\"../\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degenes = pd.read_csv('./data/final/degenes.csv', index_col=0)\n",
    "pdata = pd.read_csv('./data/final/pdata_filled.csv', index_col=0)\n",
    "\n",
    "degenes_t = degenes.T\n",
    "degenes_t.columns = [x.split('///')[0] for x in degenes_t.columns]\n",
    "degenes = degenes_t.T\n",
    "degenes = degenes/10\n",
    "degenes_t = degenes.T/10\n",
    "\n",
    "degenes_t.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata_todrop = ['cancer_status', 'subjective_assessment', '>3cm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a little bit of cluster analysis with KMeans\n",
    "# and some visualization with PCA\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "degenes_scaled = scaler.fit_transform(degenes_t)\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=42, n_init='auto')\n",
    "kmeans.fit(degenes_scaled)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_degenes = pca.fit_transform(degenes_scaled)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5), dpi=150)\n",
    "sns.scatterplot(x=pca_degenes[:,0], y=pca_degenes[:,1], hue=kmeans.labels_, ax=ax, style=pdata['cancer_status'].values, palette='GnBu_d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kdeplot of cancer status for each cluster, hue is cluster label.\n",
    "# add km labels to pdata\n",
    "pdata['Cluster'] = kmeans.labels_\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(15, 4), dpi=200, ncols=2, nrows=1)\n",
    "sns.kdeplot(data=pdata, x='cancer_status', hue='Cluster', palette='GnBu_d', ax=axs[0], fill=True, alpha=0.2)\n",
    "axs[0].set_title('Distribution of Cancer Status for Each Cluster')\n",
    "axs[0].set_xlabel('Cancer Status')\n",
    "axs[0].set_ylabel('Density')\n",
    "\n",
    "\n",
    "\n",
    "sns.countplot(data=pdata, x='Cluster', hue='cancer_status', palette='GnBu_d', ax=axs[1])\n",
    "axs[1].set_title('Count of Cancer Status for Each Cluster')\n",
    "axs[1].set_xlabel('Cluster Label')\n",
    "axs[1].set_ylabel('Count')\n",
    "axs[1].legend(title='Cancer Status')\n",
    "\n",
    "\n",
    "pdata = pdata.drop(['Cluster'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard classifiers, SVM, MLP, K-NN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn with only degenes data\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "X = degenes_t.values\n",
    "y = pdata['cancer_status'].values\n",
    "\n",
    "# standardize data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=4)\n",
    "\n",
    "# kfold cv grid search\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "params = {'n_neighbors': [3, 5, 7, 9, 11, 13, 15, 17, 19, 21]}\n",
    "scorer = make_scorer(accuracy_score)\n",
    "# f1 scorer\n",
    "f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "# make grid search with both scorers\n",
    "grid = GridSearchCV(knn, params, scoring={'accuracy': scorer, 'f1': f1_scorer}, refit='f1', cv=kfold, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# test on test set\n",
    "y_pred = grid.predict(X_test)\n",
    "knn_degenes_accuracy = accuracy_score(y_test, y_pred)\n",
    "knn_degenes_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {knn_degenes_accuracy}')\n",
    "print(f'F1 Score: {knn_degenes_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn with only pdata\n",
    "X = pdata.drop(pdata_todrop, axis=1).values\n",
    "y = pdata['cancer_status'].values\n",
    "\n",
    "# standardize data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=4)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "params = {'n_neighbors': [3, 5, 7, 9, 11, 13, 15]}\n",
    "scorer = make_scorer(accuracy_score)\n",
    "#f1 scorer\n",
    "f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "# make grid search with both scorers\n",
    "grid = GridSearchCV(knn, params, scoring={'accuracy': scorer, 'f1': f1_scorer}, refit='f1', cv=kfold, verbose=1, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# test on test set\n",
    "y_pred = grid.predict(X_test)\n",
    "knn_pdata_accuracy = accuracy_score(y_test, y_pred)\n",
    "knn_pdata_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "\n",
    "print(f'Best params: {grid.best_params_}')\n",
    "print(f'Best score: {knn_pdata_accuracy}')\n",
    "print(f'Best f1 score: {knn_pdata_f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn with both\n",
    "X = np.concatenate((degenes_t.values, pdata.drop(pdata_todrop, axis=1).values), axis=1)\n",
    "y = pdata['cancer_status'].values\n",
    "\n",
    "# standardize data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=4)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "params = {'n_neighbors': [3, 5, 7, 9, 11, 13, 15]}\n",
    "scorer = make_scorer(accuracy_score)\n",
    "f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "# make grid search with both scorers\n",
    "\n",
    "grid = GridSearchCV(knn, params, scoring={'accuracy': scorer, 'f1': f1_scorer}, refit='f1', cv=kfold, verbose=1, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# test on test set\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "\n",
    "knn_both_accuracy = accuracy_score(y_test, y_pred)\n",
    "knn_both_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Best params: {grid.best_params_}')\n",
    "print(f'Best Accuracy: {knn_both_accuracy}')\n",
    "print(f'Best F1 score: {knn_both_f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe to compare results\n",
    "results = pd.DataFrame({'Model': ['KNN', 'KNN', 'KNN'],\n",
    "                        'Data': ['DEGenes', 'PData', 'Both'],\n",
    "                        'Accuracy': [knn_degenes_accuracy, knn_pdata_accuracy, knn_both_accuracy],\n",
    "                        'F1 Score': [knn_degenes_f1, knn_pdata_f1, knn_both_f1]})\n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here svm with only gene expression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X = degenes_t.values\n",
    "y = pdata['cancer_status'].values\n",
    "\n",
    "# standardize data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=4)\n",
    "\n",
    "svm = SVC()\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "params = {'C': [0.1, 1, 10, 100, 1000],\n",
    "            'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "            'kernel': ['rbf']}\n",
    "\n",
    "scorer = make_scorer(accuracy_score)\n",
    "f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "grid = GridSearchCV(svm, params, scoring={'accuracy': scorer, 'f1': f1_scorer}, refit='f1', cv=kfold, verbose=1, n_jobs=-1) \n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# test on test set\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "svm_degenes_accuracy = accuracy_score(y_test, y_pred)\n",
    "svm_degenes_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "\n",
    "print(f'Best params: {grid.best_params_}')\n",
    "print(f'Best Accuracy: {svm_degenes_accuracy}')\n",
    "print(f'Best F1 score: {svm_degenes_f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here svm with only pdata\n",
    "X = pdata.drop(pdata_todrop, axis=1).values\n",
    "y = pdata['cancer_status'].values\n",
    "\n",
    "# standardize data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=4)\n",
    "\n",
    "svm = SVC()\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "params = {'C': [0.1, 1, 10, 100, 1000],\n",
    "            'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "            'kernel': ['rbf']}\n",
    "\n",
    "scorer = make_scorer(accuracy_score)\n",
    "f1_scorer = make_scorer(f1_score, average='weighted')  \n",
    "\n",
    "grid = GridSearchCV(svm, params, scoring={'accuracy': scorer, 'f1': f1_scorer}, refit='f1', cv=kfold, verbose=1, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# test on test set\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "svm_pdata_accuracy = accuracy_score(y_test, y_pred)\n",
    "svm_pdata_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Best params: {grid.best_params_}')\n",
    "print(f'Best Accuracy: {svm_pdata_accuracy}')\n",
    "print(f'Best F1 score: {svm_pdata_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here svm with both\n",
    "X = np.concatenate((degenes_t.values, pdata.drop(pdata_todrop, axis=1).values), axis=1)\n",
    "y = pdata['cancer_status'].values\n",
    "\n",
    "# standardize data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "svm = SVC()\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "params = {'C': [0.1, 1, 10, 100, 1000],\n",
    "            'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "            'kernel': ['rbf']}\n",
    "\n",
    "scorer = make_scorer(accuracy_score)\n",
    "f1_scorer = make_scorer(f1_score, average='weighted')   \n",
    "\n",
    "grid = GridSearchCV(svm, params, scoring={'accuracy': scorer, 'f1': f1_scorer}, refit='f1', cv=kfold, verbose=1, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "svm_both_accuracy = grid.cv_results_['mean_test_accuracy'][grid.best_index_]\n",
    "svm_both_f1 = grid.cv_results_['mean_test_f1'][grid.best_index_]\n",
    "\n",
    "print(f'Best params: {grid.best_params_}')\n",
    "print(f'Best Accuracy: {svm_both_accuracy}')\n",
    "print(f'Best F1 score: {svm_both_f1}')\n",
    "\n",
    "# create a dataframe to compare results\n",
    "results_svm = pd.DataFrame({'Model': ['SVM', 'SVM', 'SVM'],\n",
    "                        'Data': ['DEGenes', 'PData', 'Both'],\n",
    "                        'Accuracy': [svm_degenes_accuracy, svm_pdata_accuracy, svm_both_accuracy],\n",
    "                        'F1 Score': [svm_degenes_f1, svm_pdata_f1, svm_both_f1]})\n",
    "\n",
    "# concatenate results\n",
    "results = pd.concat([results, results_svm], axis=0)\n",
    "results = results.sort_values(by='F1 Score', ascending=False)\n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here random forest with only gene expression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# random search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "X = degenes_t.values\n",
    "y = pdata['cancer_status'].values\n",
    "\n",
    "# standardize data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "params = {'n_estimators': [100, 200, 300, 400, 500],\n",
    "            'max_depth': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
    "            'min_samples_split': [2, 5, 10, 15, 20],\n",
    "            'max_features': ['sqrt'],\n",
    "            'bootstrap': [True, False]}\n",
    "scorer = make_scorer(accuracy_score)\n",
    "f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "grid = RandomizedSearchCV(rf, params, scoring={'accuracy': scorer, 'f1': f1_scorer}, refit='f1', cv=kfold, verbose=1, n_jobs=-1, n_iter=32)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# test on test set\n",
    "y_pred = grid.predict(X_test)\n",
    "rf_degenes_accuracy = accuracy_score(y_test, y_pred)\n",
    "rf_degenes_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Best params: {grid.best_params_}')\n",
    "print(f'Best Accuracy: {rf_degenes_accuracy}')\n",
    "print(f'Best F1 score: {rf_degenes_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here random forest with only pdata\n",
    "X = pdata.drop(pdata_todrop, axis=1).values\n",
    "y = pdata['cancer_status'].values\n",
    "\n",
    "# standardize data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=4)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "params = {'n_estimators': [100, 200, 300, 400, 500],\n",
    "            'max_depth': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
    "            'min_samples_split': [2, 5, 10, 15, 20],\n",
    "            'max_features': ['sqrt'],\n",
    "            'bootstrap': [True, False]}\n",
    "scorer = make_scorer(accuracy_score)\n",
    "f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "grid = RandomizedSearchCV(rf, params, scoring={'accuracy': scorer, 'f1': f1_scorer}, refit='f1', cv=kfold, verbose=1, n_jobs=-1, n_iter=32)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# test on test set\n",
    "y_pred = grid.predict(X_test)\n",
    "rf_pdata_accuracy = accuracy_score(y_test, y_pred)\n",
    "rf_pdata_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Best params: {grid.best_params_}')\n",
    "print(f'Best Accuracy: {rf_pdata_accuracy}')\n",
    "print(f'Best F1 score: {rf_pdata_f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here random forest with both\n",
    "X = np.concatenate((degenes_t.values, pdata.drop(pdata_todrop, axis=1).values), axis=1)\n",
    "y = pdata['cancer_status'].values\n",
    "\n",
    "# standardize data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "params = {'n_estimators': [100, 200, 300, 400, 500],\n",
    "            'max_depth': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
    "            'min_samples_split': [2, 5, 10, 15, 20],\n",
    "            'max_features': ['sqrt'],\n",
    "            'bootstrap': [True, False]}\n",
    "scorer = make_scorer(accuracy_score)\n",
    "f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "\n",
    "grid = RandomizedSearchCV(rf, params, scoring={'accuracy': scorer, 'f1': f1_scorer}, refit='f1', cv=kfold, verbose=1, n_jobs=-1, n_iter=32)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# test on test set\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "rf_both_accuracy = grid.cv_results_['mean_test_accuracy'][grid.best_index_]\n",
    "rf_both_f1 = grid.cv_results_['mean_test_f1'][grid.best_index_]\n",
    "\n",
    "print(f'Best params: {grid.best_params_}')\n",
    "print(f'Best Accuracy: {rf_both_accuracy}')\n",
    "print(f'Best F1 score: {rf_both_f1}')\n",
    "\n",
    "# create a dataframe to compare results\n",
    "results_rf = pd.DataFrame({'Model': ['Random Forest', 'Random Forest', 'Random Forest'],\n",
    "                        'Data': ['DEGenes', 'PData', 'Both'],\n",
    "                        'Accuracy': [rf_degenes_accuracy, rf_pdata_accuracy, rf_both_accuracy],\n",
    "                        'F1 Score': [rf_degenes_f1, rf_pdata_f1, rf_both_f1]})\n",
    "# concatenate results\n",
    "results = pd.concat([results, results_rf], axis=0)\n",
    "results = results.sort_values(by='F1 Score', ascending=False)\n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP\n",
    "(the model with both DE and pdata will be taken from mlp_selection.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here mlp with only gene expression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "X = degenes_t.values\n",
    "y = pdata['cancer_status'].values\n",
    "\n",
    "# standardize data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=43)\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=43)\n",
    "\n",
    "params = {'hidden_layer_sizes': [(32,), (64,), (64, 32), (32, 32), (64,64)],\n",
    "            'activation': ['relu', 'tanh', 'logistic'],\n",
    "            'solver': ['adam'],\n",
    "            'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "            'learning_rate': ['constant', 'adaptive'], 'max_iter':[1000]}\n",
    "\n",
    "scorer = make_scorer(accuracy_score)\n",
    "f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "grid = RandomizedSearchCV(mlp, params, scoring={'accuracy': scorer, 'f1': f1_scorer}, refit='f1', cv=kfold, verbose=1, n_jobs=-1, n_iter=64)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# test on test set\n",
    "y_pred = grid.predict(X_test)\n",
    "mlp_degenes_accuracy = accuracy_score(y_test, y_pred)\n",
    "mlp_degenes_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Best params: {grid.best_params_}')\n",
    "print(f'Best Accuracy: {mlp_degenes_accuracy}')\n",
    "print(f'Best F1 score: {mlp_degenes_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here mlp with only pdata\n",
    "from sklearn.metrics import accuracy_score, make_scorer, f1_score\n",
    "\n",
    "X = pdata.drop(pdata_todrop, axis=1).values\n",
    "y = pdata['cancer_status'].values\n",
    "\n",
    "# standardize data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=41)\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "params = {'hidden_layer_sizes': [(32,), (64,), (64, 32), (32, 32), (64,64)],\n",
    "            'activation': ['relu', 'tanh', 'logistic'],\n",
    "            'solver': ['adam'],\n",
    "            'alpha': [0.001, 0.01, 0.1],\n",
    "            'learning_rate': ['constant', 'adaptive'], 'max_iter':[3000]}\n",
    "scorer = make_scorer(accuracy_score)\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "# add both scorers to grid search\n",
    "grid = GridSearchCV(mlp, params, scoring={'accuracy': scorer, 'f1': f1_scorer}, refit='accuracy', cv=kfold, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# test on test set\n",
    "y_pred = grid.predict(X_test)\n",
    "mlp_pdata_accuracy = accuracy_score(y_test, y_pred)\n",
    "mlp_pdata_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "\n",
    "print(f'Best params: {grid.best_params_}')\n",
    "print(f'Best Accuracy: {mlp_pdata_accuracy}')\n",
    "print(f'Best F1 score: {mlp_pdata_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here mlp with both \n",
    "X = np.concatenate((degenes_t.values, pdata.drop(pdata_todrop, axis=1).values), axis=1)\n",
    "y = pdata['cancer_status'].values\n",
    "\n",
    "# standardize data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_scaled)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=41)\n",
    "\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "params = {'hidden_layer_sizes': [(32,), (64,),(32, 32)],\n",
    "            'activation': ['relu', 'tanh', 'logistic'],\n",
    "            'solver': ['adam'],\n",
    "            'alpha': [0.001, 0.01, 0.1],\n",
    "            'learning_rate': ['constant', 'adaptive'], 'max_iter':[3000]}\n",
    "scorer = make_scorer(accuracy_score)\n",
    "f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "# add both scorers to grid search\n",
    "grid = GridSearchCV(mlp, params, scoring={'accuracy': scorer, 'f1': f1_scorer}, refit='accuracy', cv=kfold, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# test on test set\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "mlp_both_accuracy = accuracy_score(y_test, y_pred)\n",
    "mlp_both_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Best params: {grid.best_params_}')\n",
    "print(f'Best Accuracy: {mlp_both_accuracy}')\n",
    "print(f'Best F1 score: {mlp_both_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe to compare results\n",
    "results_mlp = pd.DataFrame({'Model': ['MLP', 'MLP', 'MLP'],\n",
    "                        'Data': ['DEGenes', 'PData', 'Both'],\n",
    "                        'Accuracy': [mlp_degenes_accuracy, mlp_pdata_accuracy, mlp_both_accuracy],\n",
    "                        'F1 Score': [mlp_degenes_f1, mlp_pdata_f1, mlp_both_f1]})\n",
    "# concatenate results\n",
    "results = pd.concat([results, results_mlp], axis=0)\n",
    "results = results.sort_values(by='F1 Score', ascending=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove gnn from results\n",
    "results = results[results['Model'] != 'GNN']\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add entry to results with Model: GNN, Data: Both, Accuracy: 0.87, F1 Score: 0.87\n",
    "gnn_df = pd.DataFrame({'Model': ['GNN'], 'Data': ['PData'], 'Accuracy': [0.86], 'F1 Score': [0.86]})\n",
    "results = pd.concat([results, gnn_df], axis=0)\n",
    "results = results.sort_values(by='F1 Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a comparison plot\n",
    "fig, ax = plt.subplots(figsize=(20,10), dpi=150)\n",
    "# barplot log scale\n",
    "sns.barplot(data=results, x='F1 Score', y='Model', hue='Data', ax=ax, palette='cool_r', orient='h')\n",
    "ax.set_xscale('log')\n",
    "# add numbers to bars\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    # not for gnn\n",
    "    if width != 0.86:\n",
    "        ax.text(width+0.005, p.get_y()+p.get_height()/2. +0.02, '{:1.2f}'.format(width), ha=\"center\")\n",
    "    else:\n",
    "        ax.text(width+0.005, p.get_y()+p.get_height()/2. +0.02, '{:1.2f}'.format(width), ha=\"center\", color='white')\n",
    "    \n",
    "ax.set_title('Comparison of F1 Score for Different Models')\n",
    "# subtitle\n",
    "ax.text(0.5, 1.05, 'Results on test set', transform=ax.transAxes, fontsize=16, ha='center')\n",
    "ax.set_xlabel('F1 Score (log scale)')\n",
    "ax.legend(title='Data')\n",
    "\n",
    "# make gnn line red\n",
    "ax.patches[0].set_facecolor('purple')\n",
    "ax.patches[0].set_edgecolor('purple')\n",
    "\n",
    "# center gnn bar\n",
    "#ax.patches[0].set_x(0)\n",
    "#ax.patches[0].set_width(0.86)\n",
    "#ax.patches[0].set_y(-0.14)\n",
    "\n",
    "# move gnn text\n",
    "#ax.text(0.86+0.006, -0.14+p.get_height()/2. +0.02, '{:1.2f}'.format(0.86), ha=\"center\", weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to structured data\n",
    "\n",
    "A plot of the graph, how we managed to build it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
